{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f912a2e7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc73e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "# from IPython.display import display\n",
    "# from keras.preprocessing.image import array_to_img\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22cd10",
   "metadata": {},
   "source": [
    "# Constans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31217e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39aadf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da8ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af93545",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_HIGHT * IMAGE_WIDTH * CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbc9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGING_PATH = 'tenserboard_handwritign_recogonition/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e8624",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8e061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314e994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2215c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed4d5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047febbf",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5951a641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c40197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd93a2",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b35f2",
   "metadata": {},
   "source": [
    "### Data Re-Scaleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "611198e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all, x_test = x_train_all / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f91eeb",
   "metadata": {},
   "source": [
    "### Convert Target Into One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff938b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_all = np.eye(NR_CLASSES)[y_train_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea27c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = np.eye(NR_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8579a49",
   "metadata": {},
   "source": [
    "### Creating Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e905bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train_all[:VALIDATION_SIZE] # OUR VALIDATION DATASET WITH 10,000 SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b223c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_train_all[:VALIDATION_SIZE] # OUR VALIDATION DATASET WITH 10,000 SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad14f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_all[VALIDATION_SIZE:] # REMOVE 10,000 (VALIDATION_SIZE) FROM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735bb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_all[VALIDATION_SIZE:] # REMOVE 10,000 (VALIDATION_SIZE) FROM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "536b6888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9c98547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16898bf4",
   "metadata": {},
   "source": [
    "# Define the Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7720112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential([\n",
    "    Dropout(0.2, seed=42, input_shape=(TOTAL_INPUTS,)),\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dropout(0.25, seed=42),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e2f1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d3f1107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 435,402\n",
      "Trainable params: 435,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45dd723",
   "metadata": {},
   "source": [
    "# TensorBoard ( Visulation Learning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73fdb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TensorBoard(model_name):\n",
    "    folder_name = f'{model_name} at {strftime(\"%H %M\")}'\n",
    "    dir_paths = os.path.join(LOGGING_PATH, folder_name)\n",
    "\n",
    "    try:\n",
    "        os.makedirs(dir_paths)\n",
    "    except OSError as err:\n",
    "        print(err.strerror)\n",
    "    else:\n",
    "        print('Seccessfully created directory')\n",
    "        \n",
    "    return TensorBoard(log_dir=dir_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0105cb",
   "metadata": {},
   "source": [
    "# Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9db70c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_batch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19136a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c45efad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seccessfully created directory\n",
      "CPU times: user 20min 1s, sys: 39.6 s, total: 20min 41s\n",
      "Wall time: 6min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f814caea4f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nr_epochs = 150\n",
    "model_1.fit(x_train, y_train, batch_size=samples_per_batch, epochs=nr_epochs, verbose=0, \n",
    "            callbacks=[get_TensorBoard('Model 1')], validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e324b2",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69a18067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAgklEQVR4nGP8z4AbMOGRo4vkq284Jd8dfsqMKsmI8MoDYV7cxjKxkOsgxn9P36JKIhn1/bTo1+8yKLL/4eDO2///L/36jwQYUQP+9W8p3A4SQAkGNElU36BJ/sMn+Ykdh+TvHwz/H4nisOT3RcZ/ihzIkihe+cyGYioD46BOYCRJAgAqIDm7RfsqzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F81499B2EB0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open('MNIST/5.png')\n",
    "new_image = image.resize((28, 28))\n",
    "new_image.save('test_resized.png')\n",
    "img = Image.open('test_resized.png')\n",
    "\n",
    "bw = img.convert('L')\n",
    "bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08c6141b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8154418d00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_array = np.invert(bw)\n",
    "# img_array = np.invert(bw)\n",
    "\n",
    "# img_array = np.array([bw])/255\n",
    "\n",
    "\n",
    "img_array = img_array/255\n",
    "plt.imshow(img_array )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a4997a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4b0e0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = img_array.ravel()\n",
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c732a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.expand_dims(test_img, axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f54fd45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [5]\n"
     ]
    }
   ],
   "source": [
    "p = model_1.predict_classes(test)\n",
    "print(f'Prediction: {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c4fd0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c0ba701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93265128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: fg: no job control\n",
      "2021-06-23 12:56:14.429511: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-06-23 12:56:14.429559: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.5.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!%%bash\n",
    "!tensorboard --logdir=/home/nachef/Desktop/tp_rdf/tenserboard_handwritign_recogonition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21c49fd6-e090-4ad9-b4d9-cf5d835b5862",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4bde2bd3b26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    457\u001b[0m                   \u001b[0;34m'  if your model does binary classification '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                   '  (e.g. if it uses a `sigmoid` last-layer activation).')\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1599\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     dataset = dataset.map(\n\u001b[0m\u001b[1;32m    388\u001b[0m         grab_batch, num_parallel_calls=dataset_ops.AUTOTUNE)\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1805\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m       return ParallelMapDataset(\n\u001b[0m\u001b[1;32m   1808\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4254\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   4255\u001b[0m         num_parallel_calls, dtype=dtypes.int64, name=\"num_parallel_calls\")\n\u001b[0;32m-> 4256\u001b[0;31m     variant_tensor = gen_dataset_ops.parallel_map_dataset_v2(\n\u001b[0m\u001b[1;32m   4257\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mparallel_map_dataset_v2\u001b[0;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, name)\u001b[0m\n\u001b[1;32m   5157\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5158\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5159\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   5160\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ParallelMapDatasetV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_arguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred=model_1.predict_classes(x_test)\n",
    "print(confusion_matrix(y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c1e50-8bff-4a5b-9ec7-3d2ab3936c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
